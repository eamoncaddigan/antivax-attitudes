---
title: "Bayesian estimation of anti-vaccination belief interventions"
author: "Eamon Caddigan"
date: "August 29, 2015"
output: html_document
---

```{r, echo=FALSE, warning=FALSE, message=FALSE, results="hide"}
library(readxl)
library(tidyr)
library(dplyr)
library(ggplot2)
library(rjags)
library(runjags)
source("DBDA2E-utilities.R")
source("ggPostPlot.R")
```

## Introduction

How easy is it to change people's attitude toward vaccinating their children? According to a study [published in PNAS](http://www.pnas.org/content/112/33/10321.abstract), a simple intervention, which consisted of showing participants images of children suffering from diseases such as rubella and measles, made participants more likely to vaccinate their children. [Here's a good writeup](https://news.illinois.edu/blog/view/6367/234202) of the article if you're unable to read the original.

The authors [placed their data online](https://osf.io/nx364/), which comprises pre- and post-intervention survey responses for three groups of participants: 

1. A control group
2. An "autism correction" group that were shown evidence that vaccines don't cause autism.
3. A "disease risk" group that were shown images of the effects of the diseases that the vaccines prevent. 

I decided to evaluate the data with a Bayesian model for a couple reasons. First, I'm friends with two of the authors (UIUC Psychologists Zach Horne and John Hummel) and it's good to see them doing cool work. Second, my own research hasn't given me much experience working with survey data, and wanted experience with a new method. I was excited to try a Bayesian approach because this lets me take a look at the data from a few different angles without having to worry about inflating the type I (false positive) error rates.

```{r, echo=FALSE}
# Generates warnings for the Ps who didn't do day 2
suppressWarnings(expData <- read_excel("Vacc_HPHH_publicDataset.xlsx", sheet = 2))

# Exclude Ps who didn't do day 2 and failed the attention checks
expData.clean <- expData %>%
  # It's good to add a subject number so we can go back to original data
  mutate(subject_number = 1:nrow(.)) %>%
  filter(Returned == 1,
         `AttentionCheck_PostTest (if = 4 then include)` == 4,
         `AttentionChecks_Sum(include if = 4)` == 4,
         Paid_Attention == 1)

# Get all the dependent measures into a DF
questionnaireData <- expData.clean %>%
  # Pull out the columns and use consistent names
  select(subject_number,
         intervention = Condition,
         pretest.healthy = Healthy_VaxscalePretest,
         posttest.healthy = Healthy_VaxscalePosttest,
         pretest.diseases = Diseases_VaxScalePretest,
         posttest.diseases = Diseases_VaxScalePosttest,
         pretest.doctors = Doctors_VaxScalePreTest,
         posttest.doctors = Doctors_VaxScalePostTest,
         pretest.side_effects = Sideeffects_VaxScalePreTest,
         posttest.side_effects = Sideeffects_VaxScalePostTest,
         pretest.plan_to = Planto_VaxScalePreTest,
         posttest.plan_to = Planto_VaxScalePostTest) %>%
  # Reverse-code the approrpiate columns
  mutate(pretest.diseases = 7 - pretest.diseases,
         posttest.diseases = 7 - posttest.diseases,
         pretest.side_effects = 7 - pretest.side_effects,
         posttest.side_effects = 7 - posttest.side_effects) %>%
  # Tidy the data
  gather("question", "response", -subject_number, -intervention) %>%
  separate(question, c("interval", "question"), sep = "\\.") %>% 
  mutate(intervention = factor(intervention, c("Control", "Autism Correction", "Disease Risk")),
         interval = factor(interval, c("pretest", "posttest"), ordered = TRUE),
         question = factor(question, c("healthy", "diseases", "doctors", "side_effects", "plan_to")))
```

Participants were given a surveys with five questions and asked to rate their level of agreement with each on a six-point scale.

code         | question
-------------|-------------
healthy      | Vaccinating healthy children helps protect others by stopping the spread of disease.
diseases     | Children do not need vaccines for diseases that are not common anymore. *reverse coded*
doctors      | Doctors would not recommend vaccines if they were unsafe.
side_effects | The risk of side effects outweighs any protective benefits of vaccines. *reverse coded*
plan_to      | I plan to vaccinate my children.

```{r, echo=FALSE, fig.width=9}
# Calculate the change-in-attitude for each subject on each question
questionnaireData <- questionnaireData %>% 
  group_by(subject_number, question) %>% 
  spread(interval, response) %>% mutate(change = posttest-pretest) %>% 
  gather("interval", "response", pretest, posttest)

p2 <- ggplot(questionnaireData, aes(x = interval, y = response, group = subject_number, color = change)) +
  geom_line(alpha = 0.2, position = position_jitter(w = 0.1, h = 0.1)) +
  facet_grid(intervention ~ question) + 
  scale_color_gradient2(low="red", mid="grey20", high="blue")
print(p2)
```

The above figure shows pre- and post-intervention responses to each question. Each line represents represents a single participant's responses before and after the intervention to a single question. Lines are colored by the magnitude of the change in response; blue lines indicate more agreement (toward a more pro-vaccine stance) and red lines indicate less agreement (a more anti-vaccine stance).

The JAGS code for the model is shown below. It's essentially a Bayesian analog to the three-factor ANOVA, using a thresholded cummulative normal distribution as a link function. Such models geenrally do a good job of capturing the ordinal responses obtained in surveys. The thresholds and variance of the link function are set separately for each question. The mean of the normal distribution is determined by a linear function of the question, the interval (pre-test vs. post-test) and intervention for each response, and all interactions between these factors. 

```{r, echo=FALSE, comment=""}
# Get the data ready for JAGS
x1 <- as.numeric(as.factor(questionnaireData[["question"]]))
Nx1Lvl <- max(x1)
x2 <- as.numeric(as.factor(questionnaireData[["intervention"]]))
Nx2Lvl <- max(x2)
x3 <- as.numeric(as.factor(questionnaireData[["interval"]]))
Nx3Lvl <- max(x3)
y <- as.numeric(questionnaireData[["response"]])
Ntotal <- length(y)
nYlevels <- max(y)  

# Threshold 1 and nYlevels-1 are fixed; other thresholds are estimated.
# This allows all parameters to be interpretable on the response scale.
thresh <- matrix(data = NA, nrow = Nx1Lvl, ncol = nYlevels-1)
thresh[, 1] <- 1 + 0.5
thresh[, nYlevels-1] <- nYlevels-1 + 0.5
# Specify the data in a list, for later shipment to JAGS:
dataList <- list(
  x1 = x1,
  Nx1Lvl = Nx1Lvl,
  x2 = x2,
  Nx2Lvl = Nx2Lvl,
  x3 = x3,
  Nx3Lvl = Nx3Lvl,
  y = y,
  NyLvl = nYlevels,
  thresh = thresh,
  Ntotal = Ntotal
)

# Prepare the model for JAGS
modelString <- "
  model {
    for (i in 1:Ntotal) {
      # Thresholded cummulative normal distribution
      y[i] ~ dcat(pr[i,1:NyLvl])
      pr[i,1] <- pnorm(thresh[x1[i], 1], mu[i], 1/sigma[x1[i]]^2)
      for (k in 2:(NyLvl-1)) {
        pr[i,k] <- max(0, pnorm(thresh[x1[i], k] ,   mu[i] , 1/sigma[x1[i]]^2 ) -
                          pnorm(thresh[x1[i], k-1] , mu[i] , 1/sigma[x1[i]]^2 ))
      }
      pr[i,NyLvl] <- 1 - pnorm(thresh[x1[i], NyLvl-1] , mu[i] , 1/sigma[x1[i]]^2)

      # mu ~ x1*x2*x3
      mu[i] <- a0 + a1[x1[i]] + a2[x2[i]] + a3[x3[i]] + 
               a1a2[x1[i], x2[i]] + a1a3[x1[i], x3[i]] + a2a3[x2[i], x3[i]] + 
               a1a2a3[x1[i], x2[i], x3[i]]
    }

    a0 ~ dnorm((1+NyLvl)/2, 1/(NyLvl)^2)

    for (j1 in 1:Nx1Lvl) { 
      # Constant sigma for beta1, we're treating all Qs as independent
      a1[j1] ~ dnorm(0.0, 1/(NyLvl)^2)

      # Sigma for normal CDF, unique for each x1.
      sigma[j1] ~ dunif(NyLvl/1000, NyLvl*10)

      # Threshold distributions. 1 and NyLvl-1 are fixed, not stochastic
      for (k in 2:(NyLvl-2)) {  
        thresh[j1, k] ~ dnorm(k+0.5, 1/2^2)
      }
    }

    # Constant sigma for beta2, the interventions are independent
    for (j2 in 1:Nx2Lvl) {
      a2[j2] ~ dnorm(0.0, 1/(NyLvl)^2)
    }

    # Constant sigma for beta3
    for (j3 in 1:Nx3Lvl) {
      a3[j3] ~ dnorm(0.0, 1/(NyLvl)^2)
    }

    # Interaction terms also have homogenous variance
    for (j1 in 1:Nx1Lvl) {
      for (j2 in 1:Nx2Lvl) {
        a1a2[j1, j2] ~ dnorm(0.0, 1/(NyLvl)^2)
      }
    }
    for (j1 in 1:Nx1Lvl) {
      for (j3 in 1:Nx3Lvl) {
        a1a3[j1, j3] ~ dnorm(0.0, 1/(NyLvl)^2)
      }
    }
    for (j2 in 1:Nx2Lvl) {
      for (j3 in 1:Nx3Lvl) {
        a2a3[j2, j3] ~ dnorm(0.0, 1/(NyLvl)^2)
      }
    }
    for (j1 in 1:Nx1Lvl) {
      for (j2 in 1:Nx2Lvl) {
        for (j3 in 1:Nx3Lvl) {
          a1a2a3[j1, j2, j3] ~ dnorm(0.0, 1/(NyLvl)^2)
        }
      }
    }

    # Compute cell means
    for (j1 in 1:Nx1Lvl) {
      for (j2 in 1:Nx2Lvl) {
        for (j3 in 1:Nx3Lvl) {
          m[j1, j2, j3] <- a0 + a1[j1] + a2[j2] + a3[j3] + 
                           a1a2[j1, j2] + a1a3[j1, j3] + a2a3[j2, j3] +
                           a1a2a3[j1, j2, j3]
        }
      }
    }

    # Convert a0, a1[], a2[], &c. to sum-to-zero b0, b1[], b2[], &c.
    b0 <- mean(m[1:Nx1Lvl, 1:Nx2Lvl, 1:Nx3Lvl])
    for (j1 in 1:Nx1Lvl) { 
      b1[j1] <- mean(m[j1, 1:Nx2Lvl, 1:Nx3Lvl]) - b0
    }
    for (j2 in 1:Nx2Lvl) { 
      b2[j2] <- mean(m[1:Nx1Lvl, j2, 1:Nx3Lvl]) - b0
    }
    for (j3 in 1:Nx3Lvl) {
      b3[j3] <- mean(m[1:Nx1Lvl, 1:Nx2Lvl, j3]) - b0
    }
    for (j1 in 1:Nx1Lvl) {
      for (j2 in 1:Nx2Lvl) {
        b1b2[j1, j2] <- mean(m[j1, j2, 1:Nx3Lvl]) - (b0 + b1[j1] + b2[j2])
      }
    }
    for (j1 in 1:Nx1Lvl) {
      for (j3 in 1:Nx3Lvl) {
        b1b3[j1, j3] <- mean(m[j1, 1:Nx2Lvl, j3]) - (b0 + b1[j1] + b3[j3])
      }
    }
    for (j2 in 1:Nx2Lvl) {
      for (j3 in 1:Nx3Lvl) {
        b2b3[j2, j3] <- mean(m[1:Nx1Lvl, j2, j3]) - (b0 + b2[j2] + b3[j3])
      }
    }
    for (j1 in 1:Nx1Lvl) {
      for (j2 in 1:Nx2Lvl) {
        for (j3 in 1:Nx3Lvl) {
          b1b2b3[j1, j2, j3] <- m[j1, j2, j3] - (b0 + b1[j1] + b2[j2] + b3[j3] + 
                                                 b1b2[j1, j2] + b1b3[j1, j3] + b2b3[j2, j3])
        }
      }
    }
  }
" # close quote for modelString
cat(modelString)
# Write out modelString to a text file
writeLines(modelString , con="TEMPmodel.txt")

# Tell JAGS which parameters to return
parameters <- c("b0", "b1", "b2", "b3", "b1b2", "b1b3", "b2b3", "b1b2b3",
                "sigma", "thresh")

# JAGS parameters. We'll let it iniaialize itself
initsList <- NULL
adaptSteps <- 500               # Number of steps to "tune" the samplers
burnInSteps <- 1000
numSavedSteps <- 15000
thinSteps <- 10
nChains <- 4
fileNameRoot <- "antivax-mcmc"

# Since running JAGS takes forever, we'll skip redoing it every time we knit.
saveName <- paste0(fileNameRoot, "-coda.Rdata")
if (file.exists(saveName)) {
  load(saveName)
} else {
  runJagsOut <- run.jags(method="parallel",
                         model="TEMPmodel.txt", 
                         monitor=parameters, 
                         data=dataList,  
                         #inits=initsList, 
                         n.chains=nChains,
                         adapt=adaptSteps,
                         burnin=burnInSteps, 
                         sample=ceiling(numSavedSteps/nChains),
                         thin=thinSteps,
                         summarise=FALSE,
                         plots=FALSE)
  codaSamples <- as.mcmc.list(runJagsOut)
  save(codaSamples, file=saveName)
}
```

## Results

### A "risk" intervention changes attitudes toward vaccination

When model parameters are fit using Monte Carlo methods, it's important to inspect the results of the sampling procedure to make sure it's well-behaved. Here's an example of one parameter, the intercept for the mean of the cummulative normal.

```{r, echo=FALSE}
diagMCMC(codaObject = codaSamples,
         parName = "b0",
         saveName = NULL)
```

It's also important to check the predictions made by a model against the data we're fitting, as "[we cannot really interpret the parameters of the model very meaningfully when the model doesn't describe the data very well](http://doingbayesiandataanalysis.blogspot.com/2015/08/a-case-in-which-metric-data-are-better.html)". Here are response histograms for each question, averaged across the levels of the other factors. Model predictions are superimposed on the histograms, along with the 95% HDI for each response.

```{r, echo=FALSE, fig.width=4, fig.height=2.5}
for (x1Level in seq_along(levels(questionnaireData$question))) {
  p <- ggPosteriorPredictive(questionnaireData, codaSamples, x1Level = x1Level)
  p <- p + ggtitle(paste("Question:", levels(questionnaireData$question)[x1Level]))
  p <- p + theme_classic()
  print(p)
}
```

Since there were no problems with sampling, and the model appears to do a good job of describing the data, we can look at parameters to see effects. First, we'll look at the interaction parameter estimates to measure the change in attitude for each intervention group.

```{r echo=FALSE, fig.width=3, fig.height=3}
mcmcMat <- as.matrix(codaSamples)

for (x2Level in seq_along(levels(questionnaireData$intervention))) {
  plotPost(mcmcMat[, paste0("b2b3[", x2Level, ",2]")] - mcmcMat[, paste0("b2b3[", x2Level, ",1]")],
           main = paste0(levels(questionnaireData$intervention)[x2Level], "\nposttest - pretest"),
           compVal = 0.0, ROPE = c(-0.05, 0.05),
           xlab = "posterior density")
}
```

Only the "disease risk" group had a positive shift in vaccination attitudes overall. We can also use the posterior distributions to directly estimate the shifts relative to the control group. 

```{r echo=FALSE, fig.width=4, fig.height=3}
controlLevel = which(levels(questionnaireData$intervention) == "Control")
for (x2Level in which(levels(questionnaireData$intervention) != "Control")) {
  plotPost((mcmcMat[, paste0("b2b3[", x2Level, ",2]")] - mcmcMat[, paste0("b2b3[", x2Level, ",1]")]) - 
             (mcmcMat[, paste0("b2b3[", controlLevel, ",2]")] - mcmcMat[, paste0("b2b3[", controlLevel, ",1]")]),
           compVal = 0.0, ROPE = c(-0.05, 0.05),
           main = paste0(levels(questionnaireData$intervention)[x2Level], "\nchange vs. Control"),
           xlab = "posterior density")
}
```

The posterior distribution above shows that "disease risk" participants shifted their response about half an interval relative to the control group following the intervention. The "autism correction" participants, however, were no more likely to vaccinate than the control group. Using Bayesian estimation, we have replicated the findings of Horne and colleagues. 
